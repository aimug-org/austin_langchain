{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05155f2-ee68-4482-b4f9-0036f4ae692d",
   "metadata": {},
   "source": [
    "# Simple LangGraph Agent with Tool Calling\n",
    "\n",
    "This notebook demonstrates how you can create a simple LangGraph agent with tool calling capabilities.  \n",
    "LangSmith traces are provided with the test runs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5caae2a-84f7-470a-9f2f-27f0521dd827",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/colinmcnamara/austin_langchain/blob/main/labs/LangChain_108/langgraph-messagegraph-ollamafunctions.ipynb)\n",
    "\n",
    "## Install and run Ollama\n",
    "\n",
    "For this lab we will download and run Ollama locally and use the `phi3` model for tool calling.  \n",
    "Adjust the below commands for your local environment.  \n",
    "This code is tested to work within Google Colab using the free tier T4 GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90f905f-3350-4ccf-bf58-eddd2ede87af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9afc73-6a43-47a9-940c-a9ddcd238714",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "ollama serve &> ollama.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b2e5b-b7e0-446c-b712-695337e51875",
   "metadata": {},
   "outputs": [],
   "source": [
    "!until ollama list; do echo waiting for ollama; sleep 5; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50aaf8db-2dfd-495b-bd2a-18c428e18dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash --bg\n",
    "ollama pull phi3 >> phi3.log 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583fc6df-c943-49d2-b284-c426e009f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!until ollama list | grep phi3; do echo waiting for phi; sleep 5; done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94e2ba-c5d0-4464-9d5f-4c6bfd03a28a",
   "metadata": {},
   "source": [
    "## Install Python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb07f6a-8877-4626-9297-b8f6966f1830",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install langchain-core==0.2.9 langchain-community==0.2.5 langchain-experimental==0.0.61 \\\n",
    "    langgraph==0.0.69 duckduckgo-search==6.1.7 httpx==0.27.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2a23e-ec5e-4a6b-8317-37292398d7a8",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425cdcdd-3cb2-408f-90bb-655e3413d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langgraph.graph import MessageGraph, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from IPython.display import display, HTML, Image\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage, ToolMessage\n",
    "from typing import List\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644620b7-3d88-4bb5-b3c7-89ecd8f05a80",
   "metadata": {},
   "source": [
    "## (Optional) Environment variables for LangSmith tracing\n",
    "\n",
    "Uncomment the code in the below cell and add your LangSmith API key to enable tracing within LangSmith."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "935bfd6d-69b5-4795-8599-452942d653ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 85;\n",
       "                var nbb_unformatted_code = \"# os.environ[\\\"LANGCHAIN_API_KEY\\\"] = \\\"xxx\\\"\\n# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n# os.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Simple Tool Calling\\\"\";\n",
       "                var nbb_formatted_code = \"# os.environ[\\\"LANGCHAIN_API_KEY\\\"] = \\\"xxx\\\"\\n# os.environ[\\\"LANGCHAIN_TRACING_V2\\\"] = \\\"true\\\"\\n# os.environ[\\\"LANGCHAIN_PROJECT\\\"] = \\\"Simple Tool Calling\\\"\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# os.environ[\"LANGCHAIN_API_KEY\"] = \"xxx\"\n",
    "# os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "# os.environ[\"LANGCHAIN_PROJECT\"] = \"Simple Tool Calling\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12717f0-be3f-4b01-a576-b70031886d2c",
   "metadata": {},
   "source": [
    "## Define Tools\n",
    "\n",
    "Here we have created 4 custom tools and used an existing tool for our toolset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90ca0dde-f220-4f8e-a8c0-be74e6bdcfac",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to multiply two numbers\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Tool to add two numbers\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def call_miracle(request: str) -> str:\n",
    "    \"\"\"Tool to call miracle\"\"\"\n",
    "    return f\"You asked for {request}, but I can't do that\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def grant_wish(wish: str) -> str:\n",
    "    \"\"\"Tool to grant wish\"\"\"\n",
    "    return f\"You asked for {wish}. Your wish is my command!\"\n",
    "\n",
    "\n",
    "tools = [multiply, add, call_miracle, grant_wish, DuckDuckGoSearchRun(max_results=2)]\n",
    "\n",
    "# tool_node will be used as a node within the LangGraph agent\n",
    "tool_node = ToolNode(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d9bc53-68c8-47f8-9e7f-a49de94568f6",
   "metadata": {},
   "source": [
    "## Initialize LLM and bind tools\n",
    "\n",
    "You can use any tool calling capable LLM along with a model that offers good JSON support.  \n",
    "We have use `OllamaFunctions` with the `phi3` model here.  \n",
    "The complete list of natively supported [LLMs with tool calling can be found here](https://python.langchain.com/v0.1/docs/integrations/chat/)  \n",
    "\n",
    "We initialize `llm` and add tools description on it by calling `bind_tools` function on it.  \n",
    "This doesn't change `llm` itself, but returns a new LLM object that is aware of the tools specifications which we store as `llm_with_tools`.  \n",
    "\n",
    "We will use `llm_with_tools` for any tool aware LLM calls and use `llm` for other, non tool related LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb412514-ec62-44ae-909e-afab0de0aada",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OllamaFunctions(model=\"phi3\", format=\"json\", temperature=0)\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d14777d-5d5f-4702-9c41-d962fbe0657c",
   "metadata": {},
   "source": [
    "## MessageGraph\n",
    "\n",
    "[MessageGraph](https://python.langchain.com/v0.1/docs/integrations/chat/) is a simple `LangGraph` state type where every node receives a list of messages as input and returns one or more messages as output.  \n",
    "\n",
    "This should be suitable for may use cases where you only need to track messages as part of the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92f699f8-6b18-4091-a36c-f0353d8677e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = MessageGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1b16ee-5a90-4b2b-8c64-217f294b4ae1",
   "metadata": {},
   "source": [
    "## Add nodes to graph\n",
    "\n",
    "Graph nodes have a name and take a callables as a second argument which are runnables that get invoked and are passed the entire state object.  \n",
    "\n",
    "Since `MessageGraph` is essentially just a collection of messages, you can use LLMs as the callable parameter.  \n",
    "\n",
    "* `oracle`: We pass `llm_with_tools` as this node with identify which tool needs to be called to complete the current request.\n",
    "* `tools`: We pass `tool_node` as the callable. If the last message in the state is an `AIMessage` with `tool_calls`, this node will use that information to call the approprtate tool from our toolset with the parameters specified in `tool_calls`.\n",
    "* `llm`: We pass `llm` as the callable. This node will take all the messages generated thus far and use that context to generate a new message. The expected outcome is the model's interpretation of the results from the tool run within the context of the initial question that was asked of the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c98683d-a279-4f64-b8cb-f7dc9e6d61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"oracle\", llm_with_tools)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "builder.add_node(\"llm\", llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d2652e-c05e-4b61-824f-c38630688b46",
   "metadata": {},
   "source": [
    "## Connect agent nodes with edges\n",
    "\n",
    "This will be a simple linear graph.\n",
    "\n",
    "* `oracle` is the entry point.\n",
    "* `tools` node will be called after `oracle`.\n",
    "* `llm` node will be called after `tools`.\n",
    "* graph ends with the execution of `llm` node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da62f02d-da29-4aad-b0b7-c26f44005d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_edge(\"oracle\", \"tools\")\n",
    "builder.add_edge(\"tools\", \"llm\")\n",
    "builder.add_edge(\"llm\", END)\n",
    "builder.set_entry_point(\"oracle\")\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cd2f6a-f94b-4f2f-b75a-1d975415c658",
   "metadata": {},
   "source": [
    "## Visualizing the graph agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280a24c9-c753-4149-8ccb-3ea2b79c5c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd380bd3-ab9a-4619-8f3d-22d29d67e909",
   "metadata": {},
   "source": [
    "## Pretty print messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db2a447e-fe52-4d70-bc65-5f2e1f763196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim_content(content: str) -> str:\n",
    "    if len(content) < 200:\n",
    "        return content\n",
    "    else:\n",
    "        return content[:200] + \"...\"\n",
    "\n",
    "\n",
    "def pretty_print(message: BaseMessage):\n",
    "    print(f\"type: {message.type}\", end=\"\")\n",
    "    if isinstance(message, AIMessage) and message.tool_calls:\n",
    "        print(f\", tool_calls: {message.tool_calls}\", end=\"\")\n",
    "    elif isinstance(message, ToolMessage):\n",
    "        print(f\", name: {message.name}\", end=\"\")\n",
    "    if message.content:\n",
    "        print(f\", content: {trim_content(message.content)}\", end=\"\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "def pretty_print_messages(messages: List[BaseMessage]):\n",
    "    [pretty_print(message) for message in messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfe6838-4fa0-4b9f-956b-8f8a6c6d492d",
   "metadata": {},
   "source": [
    "## Running the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76b7c412-df73-49e0-a00a-a7c05e2aa4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is the sum of 2 and 3?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'add', 'args': {'a': 2, 'b': 3}, 'id': 'call_322d0855fd694722a3a46d0a9402cc2a'}]\n",
      "\n",
      "type: tool, name: add, content: 5\n",
      "\n",
      "type: ai, content: The sum of 2 and 3 is 5.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is the sum of 2 and 3?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea842a2c-ee9e-46b6-af0b-a3399c541953",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/c5891130-d869-4f57-ab98-a9a264d6d524/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38fec4c8-91aa-42a4-9685-35a3f8705eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is 523 x 412?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'multiply', 'args': {'a': 523, 'b': 412}, 'id': 'call_a2cc6f7dd126441fb48c17a281eb75e9'}]\n",
      "\n",
      "type: tool, name: multiply, content: 215476\n",
      "\n",
      "type: ai, content: The result of multiplying 523 by 412 is 215,476.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is 523 x 412?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08ad7b9-0fc3-4d7b-b34a-476806fdb517",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/ca3b89f1-be50-4bda-8622-fd2ba8429230/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba663f2b-0255-4a23-9094-67f139b281f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I need a miracle. I need it to rain tomorrow.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'call_miracle', 'args': {'request': 'I need it to rain tomorrow'}, 'id': 'call_130715cf0d0f4520b4dc0af27d6d02bb'}]\n",
      "\n",
      "type: tool, name: call_miracle, content: You asked for I need it to rain tomorrow, but I can't do that\n",
      "\n",
      "type: ai, content: I'm sorry, as an AI, I don't have the ability to control weather conditions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I need a miracle. I need it to rain tomorrow.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc5e6e8-64a0-407a-93ef-eca730359c31",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/de7c375d-c0e8-49dd-9042-553d3e460451/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e805096e-a9cc-4ffc-8569-7eaa5ae4cbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: I wish for world peace.\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'grant_wish', 'args': {'wish': 'I wish for world peace.'}, 'id': 'call_61ff1c569e0845f9ba6a2b27eea18455'}]\n",
      "\n",
      "type: tool, name: grant_wish, content: You asked for I wish for world peace.. Your wish is my command!\n",
      "\n",
      "type: ai, content: That's a beautiful sentiment, and while one person's wishes can't directly change the world, it's important to remember that every positive action contributes towards peace. Let's continue working tog...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"I wish for world peace.\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d242bb-da18-4a4d-bf82-74076d49733f",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/8054cbb8-d59c-4cfc-b0ce-11b74d81f5ac/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae68d5d-9774-4319-9ed7-603d7ed440a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: Can you make it snow?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'call_miracle', 'args': {'request': 'Can you make it snow?'}, 'id': 'call_af74c0219192468d97689ddcf4f2b8b5'}]\n",
      "\n",
      "type: tool, name: call_miracle, content: You asked for Can you make it snow?, but I can't do that\n",
      "\n",
      "type: ai, content: I'm afraid I can't control the weather. However, I can provide information about snow and how to prepare for it!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"Can you make it snow?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9982e5-6e21-496c-b13f-42e532fae3ef",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/e923931d-dce8-421d-851a-5842d340aed7/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a238c49e-a7ed-4354-8478-eaee5a6be937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type: human, content: What is tomorrows weather in Austin, TX?\n",
      "\n",
      "type: ai, tool_calls: [{'name': 'duckduckgo_search', 'args': {'query': \"tomorrow's weather in Austin, Texas\"}, 'id': 'call_41bbcb587cb444cbaf058b4c34460caf'}]\n",
      "\n",
      "type: tool, name: duckduckgo_search, content: Austin Weather Forecasts. Weather Underground provides local & long-range weather forecasts, weatherreports, maps & tropical weather conditions for the Austin area. Austin TX 30.27°N 97.74°W (Elev. 50...\n",
      "\n",
      "type: ai, content: According to Weather Underground and NOAA National Weather Service, tomorrow in Austin, TX it will be mostly sunny with a high temperature of around 96°F. The heat index values could reach as high as ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke((\"human\", \"What is tomorrows weather in Austin, TX?\"))\n",
    "pretty_print_messages(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09fd4d0-e757-45cd-b0a7-80e9179800ed",
   "metadata": {},
   "source": [
    "https://smith.langchain.com/public/2c6b59d8-0611-46b2-8851-1140382587e2/r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
