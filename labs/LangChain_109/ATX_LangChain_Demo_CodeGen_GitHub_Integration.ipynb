{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LangChain GitHub Integration Demo\n",
        "\n",
        "This demo was orignially presented during the Austin LangChain User Group meetup on August 7th 2024.\n",
        "\n",
        "The demo shows a simple LangChain integration with a GitHub repository. The chain creates a GitHub pull request with generated code solutions based on a given GitHub issue inside a test project.\n",
        "\n",
        "##Links:\n",
        "presentation recording TODO\n",
        "\n",
        "*   Presentation\n",
        "*   [LangChain GitHub docs](https://python.langchain.com/v0.2/docs/integrations/tools/github/)\n",
        "*   [LangSmith Trace](https://smith.langchain.com/public/ec13afae-28a6-4eb8-8cc4-36d4bd94a3d3/r)\n",
        "\n",
        "\n",
        "##Setup\n"
      ],
      "metadata": {
        "id": "EFK0UUura-FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet  pygithub langchain langchain-community langchain-openai pygithub python-dotenv"
      ],
      "metadata": {
        "id": "VmBiqcXkj8FA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import getpass\n",
        "from langchain.agents import AgentType\n",
        "from langchain_community.agent_toolkits.github.toolkit import GitHubToolkit\n",
        "from langchain_community.utilities.github import GitHubAPIWrapper\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain import PromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.memory.summary_buffer import ConversationSummaryBufferMemory\n",
        "from langchain_core.prompts.chat import MessagesPlaceholder\n",
        "from langchain_core.tracers.context import tracing_v2_enabled"
      ],
      "metadata": {
        "id": "YzlnbBDjutJj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Required Keys and environment variables\n",
        "\n",
        "Either load the required variables from `.env` located in the project root by uncommenting `load_dotenv()` below or manually as we are doing here.\n",
        "\n",
        "You will be required to setup app authentication with GitHub. Make sure to follow [these steps](https://python.langchain.com/v0.2/docs/integrations/tools/github/#2-create-a-github-app) to link a GitHub app to your repository.\n",
        "\n",
        "Once you generate a private key for your app, you will need to load it into the notebook workspace and set `GITHUB_APP_PRIVATE_KEY` to the path of the .pem file."
      ],
      "metadata": {
        "id": "ig5LZDmvjqKF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__0A_VXaZv0J"
      },
      "outputs": [],
      "source": [
        "# load_dotenv()\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"GITHUB_APP_ID\"] = \"953998\"\n",
        "os.environ[\"GITHUB_APP_PRIVATE_KEY\"] = \"/content/codegen-langgraph.pem\" #Path to your .pem key\n",
        "\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"Enter your LangSmith API key: \")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"atx_lc_demo\"\n",
        "\n",
        "open_api_key = os.environ.get(\"OPEN_API_KEY\")\n",
        "langchain_api_key = os.environ.get(\"LANGCHAIN_API_KEY\")\n",
        "github_api_key = os.environ.get(\"GITHUB_API_KEY\")\n",
        "\n",
        "repo_issue_number = \"1\"\n",
        "github_repo = \"that1guy15/AIApp-Test\"\n",
        "github_bot_branch = f\"CodeGenBot-Test-{repo_issue_number}\"\n",
        "github_base_branch = \"main\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Instantiate the LLM and GitHub Toolkit\n",
        "`tools = toolkit.get_tools()` will load all available tools available to LangChain. This list of tools can be filtered and defined per agent if you want to limit what GitHub functionality each agent has available for use.  "
      ],
      "metadata": {
        "id": "t59ueHBhkeNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o\")\n",
        "github = GitHubAPIWrapper()\n",
        "toolkit = GitHubToolkit.from_github_api_wrapper(github)\n",
        "tools = toolkit.get_tools()\n",
        "\n",
        "print(\"Available tools:\")\n",
        "for tool in tools:\n",
        "    print(\"\\t\" + tool.name)\n",
        "print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRYcgalykwUP",
        "outputId": "64580c18-e3a1-4db0-aa38-3b9382340ea1"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available tools:\n",
            "\tGet Issues\n",
            "\tGet Issue\n",
            "\tComment on Issue\n",
            "\tList open pull requests (PRs)\n",
            "\tGet Pull Request\n",
            "\tOverview of files included in PR\n",
            "\tCreate Pull Request\n",
            "\tList Pull Requests' Files\n",
            "\tCreate File\n",
            "\tRead File\n",
            "\tUpdate File\n",
            "\tDelete File\n",
            "\tOverview of existing files in Main branch\n",
            "\tOverview of files in current working branch\n",
            "\tList branches in this repository\n",
            "\tSet active branch\n",
            "\tCreate a new branch\n",
            "\tGet files from a directory\n",
            "\tSearch issues and pull requests\n",
            "\tSearch code\n",
            "\tCreate review request\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Load and Prepare the GitHub issue"
      ],
      "metadata": {
        "id": "LWPc9AudlwU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "issue = github.get_issue(int(repo_issue_number))"
      ],
      "metadata": {
        "id": "0JuC1XMfmPpz"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To better control how the issue is presented to the agent we will use the following function to format the issue we just loaded."
      ],
      "metadata": {
        "id": "8otKzqjymW8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def format_issue(issue):\n",
        "    title = f\"Title: {issue.get('title')}.\"\n",
        "    opened_by = f\"Opened by user: {issue.get('opened_by')}\"\n",
        "    body = f\"Body: {issue.get('body')}\"\n",
        "    comments = issue.get(\"comments\")  # often too long\n",
        "    return \"\\n\".join([title, opened_by, body, comments])"
      ],
      "metadata": {
        "id": "mYU4SDH6m2kd"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Build the Agent Prompt"
      ],
      "metadata": {
        "id": "Ncxjq1KAm5fx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are an experienced software engineer that creates Pull Requests based on GitHub issues.\n",
        "\n",
        "Given the following GitHub issue:\n",
        "{issue}\n",
        "\n",
        "Your task is to:\n",
        "1. Understand the issue and the changes required.\n",
        "2. Write the necessary code to fix the issue including any existing tests.\n",
        "If no test exist covering the issue, create a new test.\n",
        "3. Create a new pull request on GitHub with the changes and link to the issue\n",
        "\n",
        "Please provide a detailed explanation of the changes you made and why you made them in the pull request message.\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"issue\"],\n",
        "    template=template,\n",
        ")\n",
        "\n",
        "final_prompt = prompt.format(issue=format_issue(issue))\n",
        "\n",
        "print(final_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBKYo8Hcm9nf",
        "outputId": "72f2b244-a7ba-4bee-89ea-7668010bab6d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are an experienced software engineer that creates Pull Requests based on GitHub issues.\n",
            "\n",
            "Given the following GitHub issue:\n",
            "Title: Filter option for get Users.\n",
            "Opened by user: that1guy15\n",
            "Body: Update the '/' GET endpoint to allow filtering based on all user properties. \r\n",
            "\r\n",
            "Here is the current function for reference:\r\n",
            "\r\n",
            "```\r\n",
            "@ns.route('/')\r\n",
            "class UserList(Resource):\r\n",
            "    '''Shows a list of all users, and lets you POST to add new users'''\r\n",
            "    @ns.doc('list_users')\r\n",
            "    @ns.marshal_list_with(user_model)\r\n",
            "    def get(self):\r\n",
            "        '''Fetch all users'''\r\n",
            "        users = mongo.db.users.find()\r\n",
            "        return list(users), 200\r\n",
            "```\n",
            "[]\n",
            "\n",
            "Your task is to:\n",
            "1. Understand the issue and the changes required.\n",
            "2. Write the necessary code to fix the issue including any existing tests. \n",
            "If no test exist covering the issue, create a new test.\n",
            "3. Create a new pull request on GitHub with the changes and link to the issue\n",
            "\n",
            "Please provide a detailed explanation of the changes you made and why you made them in the pull request message.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setup Shared memmory\n",
        "We use a seperate LLM to summarize Agent output and interaction by utilizing `ConversationSummaryBufferMemory()`. This is important to help agents understand the full context of what has happened in the chain so far."
      ],
      "metadata": {
        "id": "uH1LiCHynTWe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "summarizer_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "chat_history = MessagesPlaceholder(variable_name=\"chat_history\")\n",
        "memory = ConversationSummaryBufferMemory(\n",
        "    memory_key=\"chat_history\",\n",
        "    return_messages=True,\n",
        "    llm=summarizer_llm,\n",
        "    max_token_limit=2_000,\n",
        ")"
      ],
      "metadata": {
        "id": "y5HS2kx6n-_e"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LangChain Agent Setup\n",
        "Notice how `chat_history` and `final_prompt` are being passed into the agent under `agent_kwargs`"
      ],
      "metadata": {
        "id": "OWi-giSyoByx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,\n",
        "    handle_parsing_errors=True,  # or pass a function that accepts the error and returns a string\n",
        "    max_iterations=30,\n",
        "    max_execution_time=None,\n",
        "    early_stopping_method=\"generate\",\n",
        "    memory=memory,\n",
        "    # trim_intermediate_steps=fancier_trim_intermediate_steps,\n",
        "    agent_kwargs={\n",
        "        \"memory_prompts\": [chat_history],\n",
        "        \"input_variables\": [\"input\", \"agent_scratchpad\", \"chat_history\"],\n",
        "        \"prefix\": final_prompt,\n",
        "    },\n",
        ")"
      ],
      "metadata": {
        "id": "m6nUXR1qoHZ0"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Run the chain\n"
      ],
      "metadata": {
        "id": "uT72Dv8Woyyb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tracing_v2_enabled(\n",
        "    project_name=os.environ.get(\"LANGCHAIN_PROJECT\"), tags=[\"PR_bot\"]\n",
        ") as cb:\n",
        "    agent.run(final_prompt)"
      ],
      "metadata": {
        "id": "OTuItSRgpDec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results\n",
        "\n",
        "Once complete, you will now see a new pull request in your repository that is linked to the orignal issue. If the chain runs into issues completing the requests, it should respond in the comments of the issue."
      ],
      "metadata": {
        "id": "ATJ3ByhwpLzm"
      }
    }
  ]
}